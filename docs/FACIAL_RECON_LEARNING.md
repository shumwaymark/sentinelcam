# Facial Recognition Training and Machine Learning Pipeline

## Overview

The prototype **ML Training Pipeline** automates the training, validation, and deployment of machine
learning models for facial recognition functionality across the SentinelCam distributed system. Model 
training runs on a **Jetson Nano** (embedded ARM64 device) to maintain the philosophy of running 
exclusively on low-power embedded infrastructure.

Once proven, this becomes the foundation for future model development and the scaffolding for bespoke 
model training and retraining. For example, vehicle recognition. 

## Face Recognition Pipeline

### Data Collection


## Sentinel Task Chain


### Model Training Data Flow

```
┌──────────────────────────────────────────────────────────────┐
│ 1. Data Collection (Continuous)                              │
│    Outposts → Datasink → Sentinel                            │
│    Person detections trigger GetFaces → FaceRecon tasks      │
└──────────────────────────────────────────────────────────────┘
                            ↓
┌──────────────────────────────────────────────────────────────┐
│ 2. Curation (Manual/Semi-Automated)                          │
│    FaceSweep task runs on Sentinel: updates facelist.csv     │
│    facelist_gamma3.ipynb: Analyze recognition results        │
│    - Filter by confidence (proba > 0.99)                     │
│    - Filter by distance (< 0.65)                             │
│    - Generate montages for review                            │
│    - Flag usable images                                      │
└──────────────────────────────────────────────────────────────┘
                            ↓
┌──────────────────────────────────────────────────────────────┐
│ 3. Embedding Generation (Sentinel Task)                      │
│    FaceDataUpdate task                                       │
│    - Reads curated facelist.csv                              │
│    - Generates OpenFace embeddings                           │
│    - Outputs: facedata.hdf5                                  │
└──────────────────────────────────────────────────────────────┘
                            ↓
┌──────────────────────────────────────────────────────────────┐
│ 4. Model Training (DeepThink - Jetson Nano)                  │
│    facemodel_build_beta.ipynb executed via Papermill         │
│    - Load facedata.hdf5                                      │
│    - GridSearchCV for SVM hyperparameters                    │
│    - Train classifier on embeddings                          │
│    - Generate per-person baseline thresholds                 │
│    - Outputs:                                                │
│      • facemodel.pickle (SVM classifier)                     │
│      • baselines.hdf5 (distance thresholds)                  │
└──────────────────────────────────────────────────────────────┘
                            ↓
┌──────────────────────────────────────────────────────────────┐
│ 5. Model Deployment (Automated via Script)                   │
│    deploy_model.sh facemodel_gamma3                          │
│    - SCP model files to Sentinels                            │
│    - SCP facelist.csv to Datasinks                           │
│    - Restart services to load new model                      │
└──────────────────────────────────────────────────────────────┘
```

### Key Files and Versioning

| File | Purpose | Location | Generated By |
|------|---------|----------|--------------|
| `facelist_<version>.csv` | Current curated training data selections | Sentinel | Manual curation |
| `facedata_<version>.hdf5` | OpenFace embeddings of selected images | Sentinel | FaceDataUpdate task |
| `facemodel_<version>.pickle` | Trained SVM classifier | DeepEnd | Papermill execution |
| `baselines_<version>.hdf5` | Per-person distance thresholds | DeepEnd | Papermill execution |
| `<version>.yaml` | Training parameters (input/output filenames) | DeepEnd | Manual creation |
| `facemodel_build_beta.ipynb` | Template notebook (parameterized) | Repository | Version controlled |
| `facemodel_<version>.ipynb` | Executed notebook with results | DeepEnd | Papermill output |

**Version Naming Convention:**
- Current production: `gamma3` (facemodel_gamma3.pickle, baselines_gamma3.hdf5)
- Previous versions: beta2, beta, alpha, etc.
- Version tracks entire pipeline: embeddings → model → baselines

## Training Notebooks

### facelist_gamma3.ipynb

**Purpose:** Manual curation of face recognition results

**Key Features:**
- Load face recognition results from datasink
- Calculate statistics (confidence, distance, margins)
- Filter candidates: `proba > 0.99`, `usable == 1`, `distance < 0.65`
- Generate visual montages for review
- Export updated `facelist.csv` with selection flags

**Inputs:**
- Raw face detection/recognition data from datasink

**Outputs:**
- Curated `facelist.csv` with training selection flags

### facemodel_build_beta.ipynb (Template Notebook)

**Purpose:** Parameterized training notebook for SVM classifier

**Key Features:**
- **Parameterized cells** for version-specific inputs/outputs
- Load `facedata_<version>.hdf5` (OpenFace embeddings)
- GridSearchCV for hyperparameter tuning:
  - Kernel: RBF, Linear
  - C: Regularization strength (0.001 to 1000)
  - Gamma: Kernel coefficient (1e-1 to 1e-5)
- Train best model on full dataset
- Generate per-person baseline thresholds: `mean - std`
- Save versioned model and baselines

**Parameter Cell (Replaced by Papermill):**
```python
# parameters
facialembeddings = 'facebeta2.hdf5'      # Overridden by yaml
modelout         = 'facemodel_beta2.pickle'  # Overridden by yaml
newbaselines     = 'baselines_beta2.hdf5'    # Overridden by yaml
```

**Execution via Papermill:**
```bash
# On deepend node
papermill -f gamma3.yaml facemodel_build_beta.ipynb facemodel_gamma3.ipynb

# This:
# 1. Loads parameters from gamma3.yaml
# 2. Injects them into parameter cell
# 3. Executes all cells
# 4. Saves executed notebook as facemodel_gamma3.ipynb (with results)
# 5. Outputs facemodel_gamma3.pickle and baselines_gamma3.hdf5
```

**Version Configuration (gamma3.yaml):**
```yaml
facialembeddings: facedata_gamma3.hdf5
modelout:         facemodel_gamma3.pickle
newbaselines:     baselines_gamma3.hdf5
```

## Architecture

### Components

1. **DeepEnd Node** (Jetson Nano)
   - **Hardware**: NVIDIA Jetson Nano Developer Kit
   - **OS**: Ubuntu 18.04 (JetPack 4.6)
   - **Role**: Model training using Jupyter notebooks executed via Papermill
   - **Network**: 192.168.10.100 (deepend)

2. **Training Data Sources**
   - **Sentinel**: Provides `facelist.csv` (curated training selections)
   - **Sentinel**: Generates `facedata.hdf5` (OpenFace embeddings)

3. **Deployment Targets**
   - **Sentinels**: Receive `facemodel.pickle` and `baselines.hdf5` modeling outputs
   - **Datasinks**: Receive updated `facelist.csv` (for event retention)
   - **Outposts**: Receive models as specified (e.g., facial-recognition, vehicle recognition)

## Jetson Nano Configuration

### Why Jetson Nano for Training?

**Challenges:**
- Jetson Nano is designed for edge **inference**, not model training
- Limited RAM (4GB), slower CPU than desktop
- ARM64 architecture has fewer pre-built ML packages

**Advantages:**
- **Low power consumption** (~10W vs 200W+ for desktop GPU)
- **Embedded architecture** fits SentinelCam design philosophy
- **CUDA support** (128 cores, Maxwell architecture)
- **Always-on** availability for overnight training
- **Cost effective** (~$100 vs $1000+ for workstation)

**Trade-offs:**
- Training takes longer (overnight vs minutes)
- **This is acceptable** - training happens infrequently
- SVM training on embeddings is computationally light
- Most work already done by OpenFace (on Sentinel)
- Can be utilized for model retraining, such as for vehicle and pet recognition

### JetPack Integration

The Jetson Nano comes with **JetPack SDK** pre-installed:
- CUDA Toolkit
- cuDNN
- TensorRT
- Pre-built TensorFlow, PyTorch (for JetPack 4.6)

**Solution approach:**
- Use JetPack's system Python for CUDA-enabled packages
- Create venv for additional packages (scikit-learn, papermill)
- Let Ansible manage the venv, not JetPack packages

## Deployment Workflow

### 1. Initial Setup

```bash
# Deploy DeepThink role to Jetson Nano
cd devops/ansible
ansible-playbook playbooks/deploy-deepthink.yaml

# Verify installation
ansible ml_trainers -m command -a "/home/ops/.virtualenvs/ml-training/bin/python --version"
ansible ml_trainers -m command -a "ls -la /home/ops/deepthink/notebooks"
```

### 2. Manual Training Workflow

```bash
# SSH to deepend node
ssh pyimagesearch@deepend

# Run training script
/home/pyimagesearch/deepthink/train_face_model.sh

# Monitor output
tail -f /home/ops/sentinelcam/logs/training.log

# Once complete, deploy model
/home/ops/deepthink/deploy_model.sh facemodel_gamma3

# Restart services to load new model
ansible sentinels -a "systemctl restart sentinel"
```

### 3. Automated Training (Future)

```yaml
# Enable in host_vars/deepthink.yaml
deepthink_training_schedule:
  face_model:
    enabled: true    # Run automatically
    hour: "3"        # 3 AM daily
    minute: "0"
    day: "*"
```

## Model Deployment

### deploy_model.sh Script

Generated from Ansible template, handles:

1. **Validation**: Check model files exist
2. **Sentinel Deployment**:
   ```bash
   scp facemodel_gamma3.pickle ops@sentinel:/home/ops/sentinel/models/
   scp baselines_gamma3.hdf5 ops@sentinel:/home/ops/sentinel/models/
   ```
3. **Datasink Deployment**:
   ```bash
   scp facelist_gamma3.csv ops@data1:/home/ops/sentinelcam/faces/
   ```
4. **Verification**: SSH to targets and verify file presence

### Deployment Targets

Defined in `roles/deepthink/defaults/main.yaml`:

```yaml
deepthink_deployment_targets:
  face_model:
    sentinels:
      - sentinel
    datasinks:
      - data1
  vehicle_model:
    outposts:
      - east
      - alpha5
```

**Auto-resolves** hostnames and paths from inventory/standards.

## Version Management

### Current Versioning System

**Version naming:** `alpha`, `beta`, `beta2`, `gamma3`, etc.

**What a version represents:**
- Complete training pipeline execution
- Specific set of training data selections (facelist.csv snapshot)
- Embeddings generated from those selections
- Trained model + baselines

**Version artifacts:**
```
twister/
├── gamma3.yaml                    # Parameter file (version definition)
├── facemodel_build_beta.ipynb     # Template notebook (version controlled)
├── facemodel_gamma3.ipynb         # Executed notebook (training results/metrics)
├── facedata_gamma3.hdf5           # Embeddings for this version
├── facemodel_gamma3.pickle        # Trained model
└── baselines_gamma3.hdf5          # Per-person thresholds
```

### Tracking "Current" and "Good" Versions

**Current Challenge:** No formal tracking of which version is:
- Currently deployed in production
- Known good (validated, performs well)
- Experimental (testing new data/parameters)

**Manual Process (Current):**
1. Train new version (e.g., gamma3)
2. Review executed notebook for metrics
3. Deploy to sentinel for testing
4. Observe production performance
5. Decide to keep or rollback
6. **Problem:** No formal record of this decision

**Proposed Solution Options:**

#### Option 1: Version Metadata File
```yaml
# versions.yaml
production:
  version: gamma3
  deployed: 2025-12-01
  accuracy: 0.97
  notes: "Improved threshold calculation"
  
validated:
  - version: gamma3
    accuracy: 0.97
    validated: 2025-12-01
  - version: beta2
    accuracy: 0.95
    validated: 2025-11-15
    
experimental:
  - version: gamma4
    status: testing
    deployed: 2025-12-05
```

#### Option 2: Symlinks
```bash
# Create symlinks for known-good versions
ln -s facemodel_gamma3.pickle facemodel_production.pickle
ln -s baselines_gamma3.hdf5 baselines_production.hdf5
ln -s facemodel_beta2.pickle facemodel_validated.pickle
```

#### Option 3: Git Tags
```bash
# Tag versions in repository
git tag -a model-gamma3 -m "Production model - 97% accuracy"
git tag -a model-beta2-validated -m "Validated fallback model"
```

### Recommended Workflow

1. **Create new version**
   ```bash
   # Create parameter file
   cat > gamma4.yaml << EOF
   facialembeddings: facedata_gamma4.hdf5
   modelout:         facemodel_gamma4.pickle
   newbaselines:     baselines_gamma4.hdf5
   EOF
   ```

2. **Train model**
   ```bash
   papermill -f gamma4.yaml facemodel_build_beta.ipynb facemodel_gamma4.ipynb
   ```

3. **Review results**
   - Open `facemodel_gamma4.ipynb`
   - Check accuracy, classification report
   - Review baseline thresholds

4. **Deploy for testing**
   ```bash
   # Copy to sentinel
   scp facemodel_gamma4.pickle baselines_gamma4.hdf5 ops@sentinel:/home/ops/sentinel/models/
   
   # Restart sentinel to load new model
   ssh ops@sentinel "systemctl restart sentinel"
   ```

5. **Track deployment** (manual for now)
   - Update `versions.yaml` or symlinks
   - Note in deployment log
   - Keep previous version available for rollback

## Future Enhancements

### Short Term

1. **Automated Version Tracking**
   - Create `versions.yaml` metadata file
   - Update during deployment
   - Track: version, date, accuracy, notes

2. **Automated Training Trigger**
   - Sentinel FaceDataUpdate completes → notify DeepEnd
   - DeepEnd runs training automatically
   - Saves as new experimental version

3. **Model Validation Framework**
   - Automated accuracy checks on test set
   - Compare to production model
   - Flag for manual review if improvement > threshold

### Long Term

4. **Multi-Model Support**
   - Vehicle detection models
   - Animal detection models
   - Custom per-camera models

5. **Federated Learning**
   - Train on multiple sites' data
   - Privacy-preserving aggregation
   - Multi-site model distribution

6. **Online Learning**
   - Incremental model updates
   - Active learning from corrections
   - Continuous improvement loop

## Troubleshooting

### Training Fails with Memory Error

```bash
# Check available memory on Jetson
ssh ops@deepthink
free -h

# Reduce batch size in notebook
# Or enable swap (not recommended for SD card)
```

### Model Deployment Fails

```bash
# Check SSH connectivity
ansible sentinels -m ping
ansible datasinks -m ping

# Verify paths exist
ansible sentinels -m command -a "ls -la /home/ops/sentinel/models"

# Manual deployment
scp /home/ops/deepthink/models/facemodel_gamma3.pickle ops@sentinel:/home/ops/sentinel/models/
```

### Notebook Execution Hangs

```bash
# Check Jupyter kernel
ssh ops@deepthink
ps aux | grep jupyter

# Check training log
tail -f /home/ops/sentinelcam/logs/training.log

# Restart if needed
pkill -f jupyter
/home/ops/deepthink/train_face_model.sh
```

## Performance Notes

### Training Time Expectations

| Task | Duration (Jetson Nano) | Duration (Desktop i7) |
|------|------------------------|----------------------|
| Load HDF5 data | ~2 min | ~30 sec |
| GridSearchCV (3x5 grid) | ~4-6 hours | ~30-45 min |
| Final model training | ~10 min | ~2 min |
| **Total** | **~6 hours** | **~45 min** |

**Conclusion:** Overnight training on Jetson Nano is acceptable for infrequent retraining (weekly/monthly).

### Power Consumption

- **Jetson Nano**: ~10W (training), ~5W (idle)
- **Desktop GPU**: ~200-300W (training), ~50W (idle)
- **Annual cost difference**: ~$200/year in electricity

## Best Practices

1. **Version your models**: Use timestamp or version in filenames
2. **Test before deploying**: Validate on hold-out set
3. **Deploy during low-traffic hours**: 3-5 AM
4. **Keep backup models**: Don't overwrite previous working model
5. **Monitor performance**: Track recognition accuracy over time
6. **Document changes**: Note what training data changes affected model

## Related Documentation

- `devops/ansible/OUTPOST_REGISTRY_PATTERN.md` - Outpost configuration
- `devops/ansible/CODE_DEPLOYMENT_PATTERN.md` - Code deployment system
- `devops/ansible/VARIABLE_PRECEDENCE_MAPS.md` - Configuration hierarchy
- `sentinel/README.rst` - Sentinel task system
